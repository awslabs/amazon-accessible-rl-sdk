{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import my_nb_path  # isort: skip\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import whatif as wi\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from whatif.nbtools import pprint, print  # Enable color outputs when rich is installed.\n",
    "\n",
    "# from whatif.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-05-19 08:29:10.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mwhatif.simulator\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m417\u001b[0m - \u001b[1m{'sequences': 40, 'epochs': 5, 'batch_size': 512, 'embedding_dim': 512, 'gpt_n_layer': 1, 'gpt_n_head': 1, 'learning_rate': '6e-4', 'num_workers': 4, 'lr_decay': True}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Habana modules from /usr/local/lib64/python3.8/site-packages/habana_frameworks/torch/lib\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf5f0c86f5d44d0b7cac5d0468989cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df1be02efe04d13a864ad904d0e86c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccff1d90d23469cb194c71b10230403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efad84e53d2e4e02b239055f25e792ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e152d94ff5b40a8a350ddc7fd0fe41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-05-19 08:29:38.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mwhatif.simulator\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m445\u001b[0m - \u001b[1mTraining time in mins: 0.46\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 14.4 s, total: 1min 17s\n",
      "Wall time: 30.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mGPT\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mtok_emb\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m341\u001b[0m, \u001b[1;36m512\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mdrop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mblocks\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mBlock\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0mln1\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mln2\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mattn\u001b[1m)\u001b[0m: \u001b[1;35mCausalSelfAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mkey\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mquery\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mvalue\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mattn_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mresid_drop\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mproj\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "      \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m2048\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mln_f\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mhead\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m341\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "################################################################################\n",
    "# Load dataset\n",
    "################################################################################\n",
    "wi_df = wi.read_csv_dataset(wi.sample_dataset_path(\"chiller\"))\n",
    "wi_df.add_value()\n",
    "\n",
    "# Speed up training for demo purpose\n",
    "wi_df = wi_df.iloc[:1000]\n",
    "tokenizer = wi.AutoTokenizer(wi_df, block_size_row=2)\n",
    "# display(\n",
    "#     tokenizer.df.head(2),\n",
    "#     tokenizer.df_tokenized.head(2),\n",
    "# )\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Train simulator\n",
    "################################################################################\n",
    "# Default hyperparam is located at src/whatif/config.yaml. Alternative you can\n",
    "# (1) specify your own configuration file using config_dir and config_name, or\n",
    "# (2) passing in the configuration as parameter config.\n",
    "# Refer to GPTWrapper for more info.\n",
    "\n",
    "from habana_frameworks.torch.utils.library_loader import load_habana_module\n",
    "\n",
    "load_habana_module()\n",
    "\n",
    "model_dir = \"./\"\n",
    "model_name = \"model_chiller.pt\"\n",
    "wrapper = wi.GPTWrapper(model_dir, model_name, tokenizer)\n",
    "wrapper.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Plot\n",
    "################################################################################\n",
    "wrapper.evaluate(context_len=5, sample=False, horizon=50)\n",
    "wrapper.evaluate(context_len=5, sample=True, horizon=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Recommendation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = wi.Simulator(tokenizer, wrapper.model)\n",
    "simulator.tokenizer.df_tokenized.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a custom context sequence. \n",
    "\n",
    "**Note:** The sequence should ends with state, i.e. (s,a,r...s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_context = tokenizer.df_tokenized_seq[:7]\n",
    "custom_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One step sample\n",
    "\n",
    "`sample` returns a dataframe whose columns are (actions, reward, value, next states) given the\n",
    "context. The contents of the dataframe is in the original space (approximated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_df = simulator.sample(custom_context, max_size=10, as_token=False)\n",
    "recommendation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Your Own Planner\n",
    "\n",
    "If you want to build your own planner, `whatif` provides a few lower level api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get valid actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_valid_actions` return a dataframe of potential action (in tokenized forms) given the context.\n",
    "\n",
    "Let's get some custom context, assume always up to current states, and find out the next top_k actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_actions = simulator.get_valid_actions(custom_context, max_size=2)\n",
    "valid_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One step lookahead\n",
    "\n",
    "`lookahead` return reward and next states, given the context and action.\n",
    "\n",
    "Let pick an action to simulate the reward and next states. This api does not change the simulator internal counter and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import whatif as wi\n",
    "\n",
    "custom_context = np.array([0, 100])\n",
    "action_seq = [valid_actions.loc[0, \"chiller_configuration\"]]\n",
    "print(f\"Given the context: {custom_context} and action: {action_seq}\\n\")\n",
    "\n",
    "reward, next_states = simulator.lookahead(custom_context, action_seq)\n",
    "print(f\"{reward=}\")\n",
    "print(f\"{next_states=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym\n",
    "\n",
    "Get a gym compatible simulator using `SimulatorWrapper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_wrapper = wi.SimulatorWrapper(env=simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the action to gym encoding mapping. Gym expect action to be a list of continuous integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_wrapper.gym_action_to_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_wrapper.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, reward, done, info = sim_wrapper.step([0])\n",
    "obs, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd Party Tools "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use with 3rd party package like `stable_baseline3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "\n",
    "model = PPO(MlpPolicy, sim_wrapper, verbose=0)\n",
    "mean_reward, std_reward = evaluate_policy(model, sim_wrapper, n_eval_episodes=1)\n",
    "\n",
    "print(f\"Mean reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff232c58d1a97beb926a6d37608f9435885b0ee7bcf3f3d7f45e4c9b09443efa"
  },
  "kernelspec": {
   "display_name": "gaudi-p38",
   "language": "python",
   "name": "gaudi-p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
